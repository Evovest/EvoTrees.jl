using BenchmarkTools
using DataFrames
using CSV
using Statistics
using StatsBase: sample
using Revise
using EvoTrees
using EvoTrees: sigmoid, logit
using EvoTrees: get_gain, get_gain_q, get_max_gain, update_grads!, grow_tree, grow_gbtree, SplitInfo, Tree, TrainNode, TreeNode, Params, predict, predict!, find_split!, SplitTrack, update_track!, update_track_q!
using EvoTrees: get_edges, binarize
using EvoTrees: Quantile, Linear, Logistic, Poisson, QuantileRegression, GradientRegression

# prepare a dataset
features = rand(100, 10)
X = features
Y = rand(size(X, 1))
ğ‘– = collect(1:size(X,1))
ğ‘— = collect(1:size(X,2))

# train-eval split
ğ‘–_sample = sample(ğ‘–, size(ğ‘–, 1), replace = false)
train_size = 0.8
ğ‘–_train = ğ‘–_sample[1:floor(Int, train_size * size(ğ‘–, 1))]
ğ‘–_eval = ğ‘–_sample[floor(Int, train_size * size(ğ‘–, 1))+1:end]

X_train, X_eval = X[ğ‘–_train, :], X[ğ‘–_eval, :]
Y_train, Y_eval = Y[ğ‘–_train], Y[ğ‘–_eval]

# set parameters
loss = :linear
nrounds = 1
Î» = 1.0
Î³ = 1e-15
Î· = 0.5
max_depth = 5
min_weight = 5.0
rowsample = 1.0
colsample = 1.0
nbins = 8
Î± = 8

params1 = EvoTreeRegressor(loss=:quantile, nrounds = 1, Î±=0.5)

# initial info
Î´, Î´Â² = zeros(size(X, 1)), zeros(size(X, 1))
ğ‘¤ = ones(size(X, 1))
pred = zeros(size(Y, 1))
# @time update_grads!(Val{params1.loss}(), pred, Y, Î´, Î´Â²)
update_grads!(Val{params1.loss}(), params1.Î±, pred, Y, Î´, Î´Â², ğ‘¤)
âˆ‘Î´, âˆ‘Î´Â², âˆ‘ğ‘¤ = sum(Î´), sum(Î´Â²), sum(ğ‘¤)
gain = get_gain(âˆ‘Î´, âˆ‘Î´Â², âˆ‘ğ‘¤, params1.Î»)
gain = get_gain_q(âˆ‘Î´, âˆ‘Î´Â², âˆ‘ğ‘¤, params1.Î»)


# Calculate the gain for a given split
function bonjour(loss::T, x) where {T<:GradientRegression}
    x = x^2
    return x
end
function bonjour(loss::T, x) where {T<:QuantileRegression}
    x = x^3
    return x
end

loss = :quantile
if loss == :linear model_type = Linear()
elseif loss == :poisson model_type = Poisson()
elseif loss == :quantile model_type = Quantile()
elseif loss == :logistic model_type = Logistic()
end
