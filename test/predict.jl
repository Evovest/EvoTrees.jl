using DataFrames
using CSV
using Statistics
using Base.Threads: @threads
using StatsBase: sample

using Revise
using EvoTrees
using EvoTrees: get_gain, update_gains!, get_max_gain, update_grads!, grow_tree, grow_gbtree, SplitInfo, Tree, TrainNode, TreeNode, Params, predict, predict!, find_split!, SplitTrack, update_track!, sigmoid

# prepare a dataset
data = CSV.read("./data/performance_tot_v2_perc.csv", allowmissing = :auto)
names(data)

features = data[1:53]
X = convert(Array, features)
Y = data[54]
Y = convert(Array{Float64}, Y)
ğ‘– = collect(1:size(X,1))

# train-eval split
ğ‘–_sample = sample(ğ‘–, size(ğ‘–, 1), replace = false)
train_size = 0.8
ğ‘–_train = ğ‘–_sample[1:floor(Int, train_size * size(ğ‘–, 1))]
ğ‘–_eval = ğ‘–_sample[floor(Int, train_size * size(ğ‘–, 1))+1:end]

X_train, X_eval = X[ğ‘–_train, :], X[ğ‘–_eval, :]
Y_train, Y_eval = Y[ğ‘–_train], Y[ğ‘–_eval]

# idx
X_perm = zeros(Int, size(X))
@threads for feat in 1:size(X, 2)
    X_perm[:, feat] = sortperm(X[:, feat]) # returns gain value and idx split
    # idx[:, feat] = sortperm(view(X, :, feat)) # returns gain value and idx split
end

# placeholder for sort perm
perm_ini = zeros(Int, size(X))

# set parameters
nrounds = 1
Î» = 1.0
Î³ = 1e-15
Î· = 0.5
max_depth = 5
min_weight = 5.0
rowsample = 1.0
colsample = 1.0

# params1 = Params(nrounds, Î», Î³, Î·, max_depth, min_weight, :linear)
params1 = Params(:linear, 1, Î», Î³, 1.0, 5, min_weight, rowsample, colsample)

# initial info
Î´, Î´Â² = zeros(size(X, 1)), zeros(size(X, 1))
pred = zeros(size(Y, 1))
@time update_grads!(Val{params1.loss}(), pred, Y, Î´, Î´Â²)
# @code_warntype update_grads!(Val{params1.loss}(), pred, Y, Î´, Î´Â²)
âˆ‘Î´, âˆ‘Î´Â² = sum(Î´), sum(Î´Â²)

gain = get_gain(âˆ‘Î´, âˆ‘Î´Â², params1.Î»)
ğ‘– = collect(1:size(X,1))
ğ‘— = collect(1:size(X,2))

# initialize train_nodes
train_nodes = Vector{TrainNode}(undef, 2^params1.max_depth-1)
for feat in 1:2^params1.max_depth-1
    train_nodes[feat] = TrainNode(0, -Inf, -Inf, -Inf, [0], [0])
end

root = TrainNode(1, âˆ‘Î´, âˆ‘Î´Â², gain, ğ‘–, ğ‘—)
train_nodes[1] = root
@time tree = grow_tree(X, Î´, Î´Â², params1, perm_ini, train_nodes)

# predict - map a sample to tree-leaf prediction
@time pred = predict(tree, X)
# pred = sigmoid(pred)
sqrt(mean((pred .- Y) .^ 2))


# prediction from single tree - assign each observation to its final leaf
function predict_1(tree::Tree, X::AbstractArray{T, 2}) where T<:Real
    pred = zeros(Float64, size(X, 1))
    for i in 1:size(X, 1)
        id = Int(1)
        while tree.nodes[id].split
            if X[i, tree.nodes[id].feat] <= tree.nodes[id].cond
                id = tree.nodes[id].left
            else
                id = tree.nodes[id].right
            end
        end
        pred[i] += tree.nodes[id].pred
    end
    return pred
end

function predict_1!(pred, tree::Tree, X::AbstractArray{T, 2}) where T<:Real

    for i in 1:size(X, 1)
        id = Int(1)
        while tree.nodes[id].split
            if X[i, tree.nodes[id].feat] <= tree.nodes[id].cond
                id = tree.nodes[id].left
            else
                id = tree.nodes[id].right
            end
        end
        pred[i] += tree.nodes[id].pred
    end
    return pred
end

@time pred = predict_1(tree, X)
@code_warntype predict_1(tree, X)

pred = zeros(Float32, size(X, 1))
@code_warntype predict_1!(pred, tree, X)
@time pred = predict_1!(pred, tree, X)
@time pred = predict_2!(pred, tree, X)

sizeof(pred)/1024


mean((pred .- Y) .^ 2)


# prediction from single tree - assign each observation to its final leaf
function predict_2(tree::Tree, X::AbstractArray{T, 2}) where T<:Real
    pred = zeros(size(X, 1))
    for i in size(X, 1)
        pred[i] += tree.nodes[30].pred
    end
    return pred
end

@time pred = predict_2(tree, X)

sizeof(X)/1000
sizeof(pred)/1000
