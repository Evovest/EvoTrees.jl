using DataFrames
using CSV
using Statistics
using Base.Threads: @threads
# using BenchmarkTools
# using Profile
using StatsBase: sample

using Revise
# using Traceur
using EvoTrees
using EvoTrees: grow_tree_dev, get_gain, update_gains!, get_max_gain, update_grads!, eval_metric, grow_tree, grow_gbtree, SplitInfo, Tree, TrainNode, TreeNode, Params, predict, predict!, find_split!, SplitTrack, update_track!, sigmoid

# prepare a dataset
data = CSV.read("./data/performance_tot_v2_perc.csv", allowmissing = :auto)
names(data)

features = data[1:53]
X = convert(Matrix, features)
Y = data[54]
Y = convert(Array{Float64}, Y)
ğ‘– = collect(1:size(X,1))

# train-eval split
ğ‘–_sample = sample(ğ‘–, size(ğ‘–, 1), replace = false)
train_size = 0.8
ğ‘–_train = ğ‘–_sample[1:floor(Int, train_size * size(ğ‘–, 1))]
ğ‘–_eval = ğ‘–_sample[floor(Int, train_size * size(ğ‘–, 1))+1:end]

X_train, X_eval = X[ğ‘–_train, :], X[ğ‘–_eval, :]
Y_train, Y_eval = Y[ğ‘–_train], Y[ğ‘–_eval]

# idx
X_perm = zeros(Int, size(X))
@threads for feat in 1:size(X, 2)
    X_perm[:, feat] = sortperm(X[:, feat]) # returns gain value and idx split
    # idx[:, feat] = sortperm(view(X, :, feat)) # returns gain value and idx split
end

# placeholder for sort perm
perm_ini = zeros(Int, size(X))

# set parameters
nrounds = 1
Î» = 1.0
Î³ = 1e-15
Î· = 0.5
max_depth = 5
min_weight = 5.0
rowsample = 1.0
colsample = 1.0

# params1 = Params(nrounds, Î», Î³, Î·, max_depth, min_weight, :linear)
params1 = Params(:linear, 1, Î», Î³, 1.0, 5, min_weight, rowsample, colsample)

# initial info
Î´, Î´Â² = zeros(size(X, 1)), zeros(size(X, 1))
ğ‘¤ = ones(size(X, 1))
pred = zeros(size(Y, 1))
# @time update_grads!(Val{params1.loss}(), pred, Y, Î´, Î´Â²)
update_grads!(Val{params1.loss}(), pred, Y, Î´, Î´Â², ğ‘¤)
âˆ‘Î´, âˆ‘Î´Â², âˆ‘ğ‘¤ = sum(Î´), sum(Î´Â²), sum(ğ‘¤)

gain = get_gain(âˆ‘Î´, âˆ‘Î´Â², âˆ‘ğ‘¤, params1.Î»)
ğ‘– = collect(1:size(X,1))
ğ‘— = collect(1:size(X,2))

# initialize train_nodes
train_nodes = Vector{TrainNode}(undef, 2^params1.max_depth-1)
for feat in 1:2^params1.max_depth-1
    train_nodes[feat] = TrainNode(0, -Inf, -Inf, -Inf, -Inf, [0], [0])
end
# initializde node splits info and tracks - colsample size (ğ‘—)
splits = Vector{SplitInfo{Float64}}(undef, size(ğ‘—, 1))
for feat in 1:size(ğ‘—, 1)
    splits[feat] = SplitInfo{Float64}(-Inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -Inf, -Inf, 0, 0, 0.0)
end
tracks = Vector{SplitTrack{Float64}}(undef, size(ğ‘—, 1))
for feat in 1:size(ğ‘—, 1)
    tracks[feat] = SplitTrack{Float64}(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -Inf, -Inf, -Inf)
end

root = TrainNode(1, âˆ‘Î´, âˆ‘Î´Â², âˆ‘ğ‘¤, gain, ğ‘–, ğ‘—)
train_nodes[1] = root
@time tree = grow_tree(X, Î´, Î´Â², ğ‘¤, params1, perm_ini, train_nodes, splits, tracks)
@code_warntype grow_tree(X, Î´, Î´Â², ğ‘¤, params1, perm_ini, train_nodes, splits, tracks)

# predict - map a sample to tree-leaf prediction
# @time pred = predict(tree, X)
@time pred = predict(tree, X)
@code_warntype predict(tree, X)

# pred = sigmoid(pred)
(mean((pred .- Y) .^ 2))
# println(sort(unique(pred)))

function test_grow(n, X, Î´, Î´Â², ğ‘¤, perm_ini, params)
    for i in 1:n
        root = TrainNode(1, âˆ‘Î´, âˆ‘Î´Â², âˆ‘ğ‘¤, gain, ğ‘–, ğ‘—)
        train_nodes[1] = root
        grow_tree(X, Î´, Î´Â², ğ‘¤, params, perm_ini, train_nodes, splits, tracks)
        # grow_tree!(tree, view(X, :, :), view(Î´, :), view(Î´Â², :), params1)
    end
end

@time test_grow(1, X, Î´, Î´Â², ğ‘¤, perm_ini, params1)
@time test_grow(100, X, Î´, Î´Â², ğ‘¤, perm_ini, params1)
# @time test_grow(100, X, Î´, Î´Â², perm_ini, params1)

# full model
params1 = Params(:linear, 1, Î», Î³, 1.0, 5, min_weight, 1.0, 1.0)
@time model = grow_gbtree(X, Y, params1)
# model = grow_gbtree(X, Y, params1)

# predict - map a sample to tree-leaf prediction
# @time pred = predict(model, X)
@time pred = predict(model, X)
@code_warntype predict(model, X)

# pred = sigmoid(pred)
sqrt(mean((pred .- Y) .^ 2))


# train model
params1 = Params(:linear, 100, 0.0, 0.0, 0.1, 5, 1.0, 0.5, 0.5)
@time model = grow_gbtree(X_train, Y_train, params1, X_eval = X_eval, Y_eval = Y_eval)

@time pred_train = predict(model, X_train)
sqrt(mean((pred_train .- Y_train) .^ 2))

pred_eval = predict(model, X_eval)
sqrt(mean((pred_eval .- Y_eval) .^ 2))


####################################################
### Pred on binarised data
####################################################
X_bin = convert(Array{UInt8}, round.(X*255))
# @time test_grow(1, X_bin, Î´, Î´Â², perm_ini, params1)
# @time test_grow(10, X_bin, Î´, Î´Â², perm_ini, params1)
# @time test_grow(100, X_bin, Î´, Î´Â², perm_ini, params1)
# @time model = grow_gbtree(X_bin, Y, params1)

# test_grow(1, X_bin, Î´, Î´Â², perm_ini, params1)
# test_grow(10, X_bin, Î´, Î´Â², perm_ini, params1)
# test_grow(100, X_bin, Î´, Î´Â², perm_ini, params1)
# model = grow_gbtree(X_bin, Y, params1)

X_train_bin = convert(Array{UInt8}, round.(X_train*255))
X_eval_bin = convert(Array{UInt8}, round.(X_eval*255))

@time model = grow_gbtree(X_train_bin, Y_train, params1, X_eval = X_eval_bin, Y_eval = Y_eval)
# model = grow_gbtree(X_train_bin, Y_train, params1, X_eval = X_eval_bin, Y_eval = Y_eval)

# predict - map a sample to tree-leaf prediction
pred = predict(model, X_eval_bin)
mean((pred .- Y_eval) .^ 2)

pred = predict(model, X_train_bin)
mean((pred .- Y_train) .^ 2)

# big data test
X_train_bin2 = hcat(X_train_bin, X_train_bin, X_train_bin, X_train_bin, X_train_bin)
# X_train_bin2 = vcat(X_train_bin, X_train_bin, X_train_bin, X_train_bin, X_train_bin)
X_train_bin2 = vcat(X_train_bin2, X_train_bin2, X_train_bin2, X_train_bin2, X_train_bin2)
Y_train2 = vcat(Y_train, Y_train, Y_train, Y_train, Y_train)
@time model = grow_gbtree(X_train_bin2, Y_train2, params1)


using StatsBase
x = [11, 12, 13, 10, 15]
x_rank = ordinalrank(x)
id = [1, 3, 5]
x_view = x[id]
x_rank_view = x_rank[id]
