using DataFrames
using CSV
using Statistics
using StatsBase: sample
using Revise
using EvoTrees

# prepare a dataset
features = rand(10000) .* 20 .- 10
X = reshape(features, (size(features)[1], 1))
Y = sin.(features) .* 0.5 .+ 0.5
ğ‘– = collect(1:size(X,1))

# train-eval split
ğ‘–_sample = sample(ğ‘–, size(ğ‘–, 1), replace = false)
train_size = 0.8
ğ‘–_train = ğ‘–_sample[1:floor(Int, train_size * size(ğ‘–, 1))]
ğ‘–_eval = ğ‘–_sample[floor(Int, train_size * size(ğ‘–, 1))+1:end]

X_train, X_eval = X[ğ‘–_train, :], X[ğ‘–_eval, :]
Y_train, Y_eval = Y[ğ‘–_train], Y[ğ‘–_eval]

# set parameters
loss = :linear
nrounds = 1
Î» = 1.0
Î³ = 1e-15
Î· = 0.5
max_depth = 5
min_weight = 5.0
rowsample = 1.0
colsample = 1.0

# params1 = Params(nrounds, Î», Î³, Î·, max_depth, min_weight, :linear)
params1 = Params(:linear, 1, Î», Î³, 1.0, 5, min_weight, rowsample, colsample)

# train model
params1 = Params(:linear, 100, 0.0, 0.0, 0.1, 5, 1.0, 0.5, 1.0)
@time model = grow_gbtree(X_train, Y_train, params1, X_eval = X_eval, Y_eval = Y_eval, print_every_n = 10, metric=:none)
@time pred_train = predict(model, X_train)
sqrt(mean((pred_train .- Y_train) .^ 2))

# train model
params1 = Params(:logistic, 100, 0.0, 0.0, 0.1, 5, 1.0, 0.5, 1.0)
@time model = grow_gbtree(X_train, Y_train, params1, X_eval = X_eval, Y_eval = Y_eval, print_every_n=10, metric = :logloss)
@time pred_train = predict(model, X_train)
sqrt(mean((pred_train .- Y_train) .^ 2))
