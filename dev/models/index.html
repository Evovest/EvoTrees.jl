<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Models · EvoTrees.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/style.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="EvoTrees.jl logo"/></a><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Introduction</a></li><li class="is-active"><a class="tocitem" href>Models</a><ul class="internal"><li><a class="tocitem" href="#EvoTreeRegressor"><span>EvoTreeRegressor</span></a></li><li><a class="tocitem" href="#EvoTreeClassifier"><span>EvoTreeClassifier</span></a></li><li><a class="tocitem" href="#EvoTreeCount"><span>EvoTreeCount</span></a></li><li><a class="tocitem" href="#EvoTreeGaussian"><span>EvoTreeGaussian</span></a></li></ul></li><li><a class="tocitem" href="../api/">API</a></li><li><a class="tocitem" href="../examples-API/">Examples - API</a></li><li><a class="tocitem" href="../examples-MLJ/">Examples - MLJ</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Models</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Models</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/Evovest/EvoTrees.jl/blob/main/docs/src/models.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h2 id="EvoTreeRegressor"><a class="docs-heading-anchor" href="#EvoTreeRegressor">EvoTreeRegressor</a><a id="EvoTreeRegressor-1"></a><a class="docs-heading-anchor-permalink" href="#EvoTreeRegressor" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="EvoTrees.EvoTreeRegressor" href="#EvoTrees.EvoTreeRegressor"><code>EvoTrees.EvoTreeRegressor</code></a> — <span class="docstring-category">Type</span></header><section><div><p>EvoTreeRegressor(;kwargs...)</p><p>A model type for constructing a EvoTreeRegressor, based on <a href="https://github.com/Evovest/EvoTrees.jl">EvoTrees.jl</a>, and implementing both an internal API and the MLJ model interface.</p><p><strong>Hyper-parameters</strong></p><ul><li><p><code>loss=:linear</code>:         Loss to be be minimized during training. One of:</p><ul><li><code>:linear</code></li><li><code>:logistic</code></li><li><code>:gamma</code></li><li><code>:tweedie</code></li><li><code>:quantile</code></li><li><code>:L1</code></li></ul></li><li><p><code>nrounds=10</code>:           Number of rounds. It corresponds to the number of trees that will be sequentially stacked.</p></li><li><p><code>lambda::T=0.0</code>:        L2 regularization term on weights. Must be &gt;= 0. Higher lambda can result in a more robust model.</p></li><li><p><code>gamma::T=0.0</code>:         Minimum gain improvement needed to perform a node split. Higher gamma can result in a more robust model.</p></li><li><p><code>alpha::T=0.5</code>:         Loss specific parameter in the [0, 1] range:                           - <code>:quantile</code>: target quantile for the regression.                           - <code>:L1</code>: weighting parameters to positive vs negative residuals.                                 - Positive residual weights = <code>alpha</code>                                 - Negative residual weights = <code>(1 - alpha)</code></p></li><li><p><code>max_depth=5</code>:          Maximum depth of a tree. Must be &gt;= 1. A tree of depth 1 is made of a single prediction leaf. A complete tree of depth N contains <code>2^(N - 1)</code> terminal leaves and <code>2^(N - 1) - 1</code> split nodes. Compute cost is proportional to <code>2^max_depth</code>. Typical optimal values are in the 3 to 9 range.</p></li><li><p><code>min_weight=0.0</code>:       Minimum weight needed in a node to perform a split. Matches the number of observations by default or the sum of weights as provided by the <code>weights</code> vector.</p></li><li><p><code>rowsample=1.0</code>:        Proportion of rows that are sampled at each iteration to build the tree. Should be in <code>]0, 1]</code>.</p></li><li><p><code>colsample=1.0</code>:        Proportion of columns / features that are sampled at each iteration to build the tree. Should be in <code>]0, 1]</code>.</p></li><li><p><code>nbins=32</code>:             Number of bins into which each feature is quantized. Buckets are defined based on quantiles, hence resulting in equal weight bins.</p></li><li><p><code>monotone_constraints=Dict{Int, Int}()</code>: Specify monotonic constraints using a dict where the key is the feature index and the value the applicable constraint (-1=decreasing, 0=none, 1=increasing).  Only <code>:linear</code>, <code>:logistic</code>, <code>:gamma</code> and <code>tweedie</code> losses are supported at the moment.</p></li><li><p><code>rng=123</code>:              Either an integer used as a seed to the random number generator or an actual random number generator (<code>::Random.AbstractRNG</code>).</p></li><li><p><code>device=&quot;cpu&quot;</code>:         Hardware device to use for computations. Can be either <code>&quot;cpu&quot;</code> or <code>&quot;gpu&quot;</code>. Only <code>:linear</code>, <code>:logistic</code>, <code>:gamma</code> and <code>tweedie</code> losses are supported on GPU.</p></li></ul><p><strong>Internal API</strong></p><p>Do <code>config = EvoTreeRegressor()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in EvoTreeRegressor(loss=...).</p><p><strong>Training model</strong></p><p>A model is built using <a href="../api/#EvoTrees.fit_evotree"><code>fit_evotree</code></a>:</p><pre><code class="language-julia hljs">model = fit_evotree(config; x_train, y_train, kwargs...)</code></pre><p><strong>Inference</strong></p><p>Predictions are obtained using <a href="@ref"><code>predict</code></a> which returns a <code>Matrix</code> of size <code>[nobs, 1]</code>:</p><pre><code class="language-julia hljs">EvoTrees.predict(model, X)</code></pre><p>Alternatively, models act as a functor, returning predictions when called as a function with features as argument:</p><pre><code class="language-julia hljs">model(X)</code></pre><p><strong>MLJ Interface</strong></p><p>From MLJ, the type can be imported using:</p><pre><code class="language-julia hljs">EvoTreeRegressor = @load EvoTreeRegressor pkg=EvoTrees</code></pre><p>Do <code>model = EvoTreeRegressor()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>EvoTreeRegressor(loss=...)</code>.</p><p><strong>Training model</strong></p><p>In MLJ or MLJBase, bind an instance <code>model</code> to data with     <code>mach = machine(model, X, y)</code> where</p><ul><li><code>X</code>: any table of input features (eg, a <code>DataFrame</code>) whose columns each have one of the following element scitypes: <code>Continuous</code>, <code>Count</code>, or <code>&lt;:OrderedFactor</code>; check column scitypes with <code>schema(X)</code></li><li><code>y</code>: is the target, which can be any <code>AbstractVector</code> whose element scitype is <code>&lt;:Continuous</code>; check the scitype with <code>scitype(y)</code></li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><p><strong>Operations</strong></p><ul><li><code>predict(mach, Xnew)</code>: return predictions of the target given features <code>Xnew</code> having the same scitype as <code>X</code> above. Predictions are deterministic.</li></ul><p><strong>Fitted parameters</strong></p><p>The fields of <code>fitted_params(mach)</code> are:</p><ul><li><code>:fitresult</code>: The <code>GBTree</code> object returned by EvoTrees.jl fitting algorithm.</li></ul><p><strong>Report</strong></p><p>The fields of <code>report(mach)</code> are:</p><ul><li><code>:features</code>: The names of the features encountered in training.</li></ul><p><strong>Examples</strong></p><pre><code class="nohighlight hljs"># Internal API
using EvoTrees
config = EvoTreeRegressor(max_depth=5, nbins=32, nrounds=100)
nobs, nfeats = 1_000, 5
x_train, y_train = randn(nobs, nfeats), rand(nobs)
model = fit_evotree(config; x_train, y_train)
preds = EvoTrees.predict(model, x_train)</code></pre><pre><code class="nohighlight hljs"># MLJ Interface
using MLJ
EvoTreeRegressor = @load EvoTreeRegressor pkg=EvoTrees
model = EvoTreeRegressor(max_depth=5, nbins=32, nrounds=100)
X, y = @load_boston
mach = machine(model, X, y) |&gt; fit!
preds = predict(mach, X)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Evovest/EvoTrees.jl/blob/c1b1c9917af55025d9b8efe3ce6b67b718d10634/src/MLJ.jl#L169-L292">source</a></section></article><h2 id="EvoTreeClassifier"><a class="docs-heading-anchor" href="#EvoTreeClassifier">EvoTreeClassifier</a><a id="EvoTreeClassifier-1"></a><a class="docs-heading-anchor-permalink" href="#EvoTreeClassifier" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="EvoTrees.EvoTreeClassifier" href="#EvoTrees.EvoTreeClassifier"><code>EvoTrees.EvoTreeClassifier</code></a> — <span class="docstring-category">Type</span></header><section><div><p>EvoTreeClassifier(;kwargs...)</p><p>A model type for constructing a EvoTreeClassifier, based on <a href="https://github.com/Evovest/EvoTrees.jl">EvoTrees.jl</a>, and implementing both an internal API and the MLJ model interface. EvoTreeClassifier is used to perform multi-class classification, using cross-entropy loss.</p><p><strong>Hyper-parameters</strong></p><ul><li><code>nrounds=10</code>:                 Number of rounds. It corresponds to the number of trees that will be sequentially stacked.</li><li><code>lambda::T=0.0</code>:              L2 regularization term on weights. Must be &gt;= 0. Higher lambda can result in a more robust model.</li><li><code>gamma::T=0.0</code>:               Minimum gain improvement needed to perform a node split. Higher gamma can result in a more robust model.</li><li><code>max_depth=5</code>:                Maximum depth of a tree. Must be &gt;= 1. A tree of depth 1 is made of a single prediction leaf. A complete tree of depth N contains <code>2^(N - 1)</code> terminal leaves and <code>2^(N - 1) - 1</code> split nodes. Compute cost is proportional to <code>2^max_depth</code>. Typical optimal values are in the 3 to 9 range.</li><li><code>min_weight=0.0</code>:             Minimum weight needed in a node to perform a split. Matches the number of observations by default or the sum of weights as provided by the <code>weights</code> vector.</li><li><code>rowsample=1.0</code>:              Proportion of rows that are sampled at each iteration to build the tree. Should be in <code>]0, 1]</code>.</li><li><code>colsample=1.0</code>:              Proportion of columns / features that are sampled at each iteration to build the tree. Should be in <code>]0, 1]</code>.</li><li><code>nbins=32</code>:                   Number of bins into which each feature is quantized. Buckets are defined based on quantiles, hence resulting in equal weight bins.</li><li><code>rng=123</code>:                    Either an integer used as a seed to the random number generator or an actual random number generator (<code>::Random.AbstractRNG</code>).</li><li><code>device=&quot;cpu&quot;</code>:               Hardware device to use for computations. Can be either <code>&quot;cpu&quot;</code> or <code>&quot;gpu&quot;</code>.</li></ul><p><strong>Internal API</strong></p><p>Do <code>config = EvoTreeClassifier()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in EvoTreeClassifier(max_depth=...).</p><p><strong>Training model</strong></p><p>A model is built using <a href="../api/#EvoTrees.fit_evotree"><code>fit_evotree</code></a>:</p><pre><code class="language-julia hljs">model = fit_evotree(config; x_train, y_train, kwargs...)</code></pre><p><strong>Inference</strong></p><p>Predictions are obtained using <a href="@ref"><code>predict</code></a> which returns a <code>Matrix</code> of size <code>[nobs, K]</code> where <code>K</code> is the number of classes:</p><pre><code class="language-julia hljs">EvoTrees.predict(model, X)</code></pre><p>Alternatively, models act as a functor, returning predictions when called as a function with features as argument:</p><pre><code class="language-julia hljs">model(X)</code></pre><p><strong>MLJ</strong></p><p>From MLJ, the type can be imported using:</p><pre><code class="language-julia hljs">EvoTreeClassifier = @load EvoTreeClassifier pkg=EvoTrees</code></pre><p>Do <code>model = EvoTreeClassifier()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>EvoTreeClassifier(loss=...)</code>.</p><p><strong>Training data</strong></p><p>In MLJ or MLJBase, bind an instance <code>model</code> to data with</p><pre><code class="nohighlight hljs">mach = machine(model, X, y)</code></pre><p>where</p><ul><li><code>X</code>: any table of input features (eg, a <code>DataFrame</code>) whose columns each have one of the following element scitypes: <code>Continuous</code>, <code>Count</code>, or <code>&lt;:OrderedFactor</code>; check column scitypes with <code>schema(X)</code></li><li><code>y</code>: is the target, which can be any <code>AbstractVector</code> whose element scitype is <code>&lt;:Multiclas</code> or <code>&lt;:OrderedFactor</code>; check the scitype with <code>scitype(y)</code></li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><p><strong>Operations</strong></p><ul><li><p><code>predict(mach, Xnew)</code>: return predictions of the target given features <code>Xnew</code> having the same scitype as <code>X</code> above. Predictions are probabilistic.</p></li><li><p><code>predict_mode(mach, Xnew)</code>: returns the mode of each of the prediction above.</p></li></ul><p><strong>Fitted parameters</strong></p><p>The fields of <code>fitted_params(mach)</code> are:</p><ul><li><code>:fitresult</code>: The <code>GBTree</code> object returned by EvoTrees.jl fitting algorithm.</li></ul><p><strong>Report</strong></p><p>The fields of <code>report(mach)</code> are:</p><ul><li><code>:features</code>: The names of the features encountered in training.</li></ul><p><strong>Examples</strong></p><pre><code class="nohighlight hljs"># Internal API
using EvoTrees
config = EvoTreeClassifier(max_depth=5, nbins=32, nrounds=100)
nobs, nfeats = 1_000, 5
x_train, y_train = randn(nobs, nfeats), rand(1:3, nobs)
model = fit_evotree(config; x_train, y_train)
preds = EvoTrees.predict(model, x_train)</code></pre><pre><code class="nohighlight hljs"># MLJ Interface
using MLJ
EvoTreeClassifier = @load EvoTreeClassifier pkg=EvoTrees
model = EvoTreeClassifier(max_depth=5, nbins=32, nrounds=100)
X, y = @load_iris
mach = machine(model, X, y) |&gt; fit!
preds = predict(mach, X)
preds = predict_mode(mach, X)</code></pre><p>See also <a href="https://github.com/Evovest/EvoTrees.jl">EvoTrees.jl</a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Evovest/EvoTrees.jl/blob/c1b1c9917af55025d9b8efe3ce6b67b718d10634/src/MLJ.jl#L296-L413">source</a></section></article><h2 id="EvoTreeCount"><a class="docs-heading-anchor" href="#EvoTreeCount">EvoTreeCount</a><a id="EvoTreeCount-1"></a><a class="docs-heading-anchor-permalink" href="#EvoTreeCount" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="EvoTrees.EvoTreeCount" href="#EvoTrees.EvoTreeCount"><code>EvoTrees.EvoTreeCount</code></a> — <span class="docstring-category">Type</span></header><section><div><p>EvoTreeCount(;kwargs...)</p><p>A model type for constructing a EvoTreeCount, based on <a href="https://github.com/Evovest/EvoTrees.jl">EvoTrees.jl</a>, and implementing both an internal API the MLJ model interface. EvoTreeCount is used to perform Poisson probabilistic regression on count target.</p><p><strong>Hyper-parameters</strong></p><ul><li><code>nrounds=10</code>:                 Number of rounds. It corresponds to the number of trees that will be sequentially stacked.</li><li><code>lambda::T=0.0</code>:              L2 regularization term on weights. Must be &gt;= 0. Higher lambda can result in a more robust model.</li><li><code>gamma::T=0.0</code>:               Minimum gain imprvement needed to perform a node split. Higher gamma can result in a more robust model.</li><li><code>max_depth=5</code>:                Maximum depth of a tree. Must be &gt;= 1. A tree of depth 1 is made of a single prediction leaf. A complete tree of depth N contains <code>2^(N - 1)</code> terminal leaves and <code>2^(N - 1) - 1</code> split nodes. Compute cost is proportional to 2^max_depth. Typical optimal values are in the 3 to 9 range.</li><li><code>min_weight=0.0</code>:             Minimum weight needed in a node to perform a split. Matches the number of observations by default or the sum of weights as provided by the <code>weights</code> vector.</li><li><code>rowsample=1.0</code>:              Proportion of rows that are sampled at each iteration to build the tree. Should be <code>]0, 1]</code>.</li><li><code>colsample=1.0</code>:              Proportion of columns / features that are sampled at each iteration to build the tree. Should be <code>]0, 1]</code>.</li><li><code>nbins=32</code>:                   Number of bins into which each feature is quantized. Buckets are defined based on quantiles, hence resulting in equal weight bins.</li><li><code>monotone_constraints=Dict{Int, Int}()</code>: Specify monotonic constraints using a dict where the key is the feature index and the value the applicable constraint (-1=decreasing, 0=none, 1=increasing).</li><li><code>rng=123</code>:                    Either an integer used as a seed to the random number generator or an actual random number generator (<code>::Random.AbstractRNG</code>).</li><li><code>device=&quot;cpu&quot;</code>:               Hardware device to use for computations. Can be either <code>&quot;cpu&quot;</code> or <code>&quot;gpu&quot;</code>.</li></ul><p><strong>Internal API</strong></p><p>Do <code>config = EvoTreeCount()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in EvoTreeCount(max_depth=...).</p><p><strong>Training model</strong></p><p>A model is built using <a href="../api/#EvoTrees.fit_evotree"><code>fit_evotree</code></a>:</p><pre><code class="language-julia hljs">model = fit_evotree(config; x_train, y_train, kwargs...)</code></pre><p><strong>Inference</strong></p><p>Predictions are obtained using <a href="@ref"><code>predict</code></a> which returns a <code>Matrix</code> of size <code>[nobs, 1]</code>:</p><pre><code class="language-julia hljs">EvoTrees.predict(model, X)</code></pre><p>Alternatively, models act as a functor, returning predictions when called as a function with features as argument:</p><pre><code class="language-julia hljs">model(X)</code></pre><p><strong>MLJ</strong></p><p>From MLJ, the type can be imported using:</p><pre><code class="language-julia hljs">EvoTreeCount = @load EvoTreeCount pkg=EvoTrees</code></pre><p>Do <code>model = EvoTreeCount()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>EvoTreeCount(loss=...)</code>.</p><p><strong>Training data</strong></p><p>In MLJ or MLJBase, bind an instance <code>model</code> to data with     mach = machine(model, X, y) where</p><ul><li><code>X</code>: any table of input features (eg, a <code>DataFrame</code>) whose columns each have one of the following element scitypes: <code>Continuous</code>, <code>Count</code>, or <code>&lt;:OrderedFactor</code>; check column scitypes with <code>schema(X)</code></li><li><code>y</code>: is the target, which can be any <code>AbstractVector</code> whose element scitype is <code>&lt;:Count</code>; check the scitype with <code>scitype(y)</code></li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><p><strong>Operations</strong></p><ul><li><code>predict(mach, Xnew)</code>: returns a vector of Poisson distributions given features <code>Xnew</code> having the same scitype as <code>X</code> above. Predictions are probabilistic.</li></ul><p>Specific metrics can also be predicted using:</p><ul><li><code>predict_mean(mach, Xnew)</code></li><li><code>predict_mode(mach, Xnew)</code></li><li><code>predict_median(mach, Xnew)</code></li></ul><p><strong>Fitted parameters</strong></p><p>The fields of <code>fitted_params(mach)</code> are:</p><ul><li><code>:fitresult</code>: The <code>GBTree</code> object returned by EvoTrees.jl fitting algorithm.</li></ul><p><strong>Report</strong></p><p>The fields of <code>report(mach)</code> are:</p><ul><li><code>:features</code>: The names of the features encountered in training.</li></ul><p><strong>Examples</strong></p><pre><code class="nohighlight hljs"># Internal API
using EvoTrees
config = EvoTreeCount(max_depth=5, nbins=32, nrounds=100)
nobs, nfeats = 1_000, 5
x_train, y_train = randn(nobs, nfeats), rand(0:2, nobs)
model = fit_evotree(config; x_train, y_train)
preds = EvoTrees.predict(model, x_train)</code></pre><pre><code class="nohighlight hljs">using MLJ
EvoTreeCount = @load EvoTreeCount pkg=EvoTrees
model = EvoTreeCount(max_depth=5, nbins=32, nrounds=100)
nobs, nfeats = 1_000, 5
X, y = randn(nobs, nfeats), rand(0:2, nobs)
mach = machine(model, X, y) |&gt; fit!
preds = predict(mach, X)
preds = predict_mean(mach, X)
preds = predict_mode(mach, X)
preds = predict_median(mach, X)
</code></pre><p>See also <a href="https://github.com/Evovest/EvoTrees.jl">EvoTrees.jl</a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Evovest/EvoTrees.jl/blob/c1b1c9917af55025d9b8efe3ce6b67b718d10634/src/MLJ.jl#L416-L538">source</a></section></article><h2 id="EvoTreeGaussian"><a class="docs-heading-anchor" href="#EvoTreeGaussian">EvoTreeGaussian</a><a id="EvoTreeGaussian-1"></a><a class="docs-heading-anchor-permalink" href="#EvoTreeGaussian" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="EvoTrees.EvoTreeGaussian" href="#EvoTrees.EvoTreeGaussian"><code>EvoTrees.EvoTreeGaussian</code></a> — <span class="docstring-category">Type</span></header><section><div><p>EvoTreeGaussian(;kwargs...)</p><p>A model type for constructing a EvoTreeGaussian, based on <a href="https://github.com/Evovest/EvoTrees.jl">EvoTrees.jl</a>, and implementing both an internal API the MLJ model interface. EvoTreeGaussian is used to perform Gaussian probabilistic regression, fitting μ and σ parameters to maximize likelihood.</p><p><strong>Hyper-parameters</strong></p><ul><li><code>nrounds=10</code>:                 Number of rounds. It corresponds to the number of trees that will be sequentially stacked.</li><li><code>lambda::T=0.0</code>:              L2 regularization term on weights. Must be &gt;= 0. Higher lambda can result in a more robust model.</li><li><code>gamma::T=0.0</code>:               Minimum gain imprvement needed to perform a node split. Higher gamma can result in a more robust model.</li><li><code>max_depth=5</code>:                Maximum depth of a tree. Must be &gt;= 1. A tree of depth 1 is made of a single prediction leaf. A complete tree of depth N contains <code>2^(N - 1)</code> terminal leaves and <code>2^(N - 1) - 1</code> split nodes. Compute cost is proportional to 2^max_depth. Typical optimal values are in the 3 to 9 range.</li><li><code>min_weight=0.0</code>:             Minimum weight needed in a node to perform a split. Matches the number of observations by default or the sum of weights as provided by the <code>weights</code> vector.</li><li><code>rowsample=1.0</code>:              Proportion of rows that are sampled at each iteration to build the tree. Should be in <code>]0, 1]</code>.</li><li><code>colsample=1.0</code>:              Proportion of columns / features that are sampled at each iteration to build the tree. Should be in <code>]0, 1]</code>.</li><li><code>nbins=32</code>:                   Number of bins into which each feature is quantized. Buckets are defined based on quantiles, hence resulting in equal weight bins.</li><li><code>monotone_constraints=Dict{Int, Int}()</code>: Specify monotonic constraints using a dict where the key is the feature index and the value the applicable constraint (-1=decreasing, 0=none, 1=increasing).  !Experimental feature: note that for Gaussian regression, constraints may not be enforce systematically.</li><li><code>rng=123</code>:                    Either an integer used as a seed to the random number generator or an actual random number generator (<code>::Random.AbstractRNG</code>).</li><li><code>metric::Symbol=:none</code>:       Metric that is to be tracked during the training process. One of: <code>:none</code>, <code>:gaussian</code>.</li><li><code>device=&quot;cpu&quot;</code>:               Hardware device to use for computations. Can be either <code>&quot;cpu&quot;</code> or <code>&quot;gpu&quot;</code>.</li></ul><p><strong>Internal API</strong></p><p>Do <code>config = EvoTreeGaussian()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in EvoTreeGaussian(max_depth=...).</p><p><strong>Training model</strong></p><p>A model is built using <a href="../api/#EvoTrees.fit_evotree"><code>fit_evotree</code></a>:</p><pre><code class="language-julia hljs">model = fit_evotree(config; x_train, y_train, kwargs...)</code></pre><p><strong>Inference</strong></p><p>Predictions are obtained using <a href="@ref"><code>predict</code></a> which returns a <code>Matrix</code> of size <code>[nobs, 2]</code> where the second dimensions refer to <code>μ</code> and <code>σ</code> respectively:</p><pre><code class="language-julia hljs">EvoTrees.predict(model, X)</code></pre><p>Alternatively, models act as a functor, returning predictions when called as a function with features as argument:</p><pre><code class="language-julia hljs">model(X)</code></pre><p><strong>MLJ</strong></p><p>From MLJ, the type can be imported using:</p><pre><code class="language-julia hljs">EvoTreeGaussian = @load EvoTreeGaussian pkg=EvoTrees</code></pre><p>Do <code>model = EvoTreeGaussian()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>EvoTreeGaussian(loss=...)</code>.</p><p><strong>Training data</strong></p><p>In MLJ or MLJBase, bind an instance <code>model</code> to data with</p><pre><code class="nohighlight hljs">mach = machine(model, X, y)</code></pre><p>where</p><ul><li><p><code>X</code>: any table of input features (eg, a <code>DataFrame</code>) whose columns each have one of the following element scitypes: <code>Continuous</code>, <code>Count</code>, or <code>&lt;:OrderedFactor</code>; check column scitypes with <code>schema(X)</code></p></li><li><p><code>y</code>: is the target, which can be any <code>AbstractVector</code> whose element scitype is <code>&lt;:Continuous</code>; check the scitype with <code>scitype(y)</code></p></li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><p><strong>Operations</strong></p><ul><li><code>predict(mach, Xnew)</code>: returns a vector of Gaussian distributions given features <code>Xnew</code> having the same scitype as <code>X</code> above.</li></ul><p>Predictions are probabilistic.</p><p>Specific metrics can also be predicted using:</p><ul><li><code>predict_mean(mach, Xnew)</code></li><li><code>predict_mode(mach, Xnew)</code></li><li><code>predict_median(mach, Xnew)</code></li></ul><p><strong>Fitted parameters</strong></p><p>The fields of <code>fitted_params(mach)</code> are:</p><ul><li><code>:fitresult</code>: The <code>GBTree</code> object returned by EvoTrees.jl fitting algorithm.</li></ul><p><strong>Report</strong></p><p>The fields of <code>report(mach)</code> are:</p><ul><li><code>:features</code>: The names of the features encountered in training.</li></ul><p><strong>Examples</strong></p><pre><code class="nohighlight hljs"># Internal API
using EvoTrees
params = EvoTreeGaussian(max_depth=5, nbins=32, nrounds=100)
nobs, nfeats = 1_000, 5
x_train, y_train = randn(nobs, nfeats), rand(nobs)
model = fit_evotree(params; x_train, y_train)
preds = EvoTrees.predict(model, x_train)</code></pre><pre><code class="nohighlight hljs"># MLJ Interface
using MLJ
EvoTreeGaussian = @load EvoTreeGaussian pkg=EvoTrees
model = EvoTreeGaussian(max_depth=5, nbins=32, nrounds=100)
X, y = @load_boston
mach = machine(model, X, y) |&gt; fit!
preds = predict(mach, X)
preds = predict_mean(mach, X)
preds = predict_mode(mach, X)
preds = predict_median(mach, X)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Evovest/EvoTrees.jl/blob/c1b1c9917af55025d9b8efe3ce6b67b718d10634/src/MLJ.jl#L541-L667">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Introduction</a><a class="docs-footer-nextpage" href="../api/">API »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Monday 7 November 2022 03:39">Monday 7 November 2022</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
