using Statistics
using StatsBase: sample
using Revise
using EvoTrees
using BenchmarkTools

# prepare a dataset
features = rand(Int(1.25e6), 100)
# features = rand(100, 10)
X = features
Y = rand(size(X, 1))
ğ‘– = collect(1:size(X, 1))

# train-eval split
ğ‘–_sample = sample(ğ‘–, size(ğ‘–, 1), replace=false)
train_size = 0.8
ğ‘–_train = ğ‘–_sample[1:floor(Int, train_size * size(ğ‘–, 1))]
ğ‘–_eval = ğ‘–_sample[floor(Int, train_size * size(ğ‘–, 1)) + 1:end]

X_train, X_eval = X[ğ‘–_train, :], X[ğ‘–_eval, :]
Y_train, Y_eval = Y[ğ‘–_train], Y[ğ‘–_eval]

params_c = EvoTreeRegressor(T=Float32,
    loss=:linear, metric=:none,
    nrounds=100,
    Î»=1.0, Î³=0.1, Î·=0.1,
    max_depth=6, min_weight=1.0,
    rowsample=1.0, colsample=1.0, nbins=32);

model_c, cache_c = EvoTrees.init_evotree(params_c, X_train, Y_train);

# initialize from cache
params_c = model_c.params
train_nodes = cache_c.train_nodes
splits = cache_c.splits
X_size = size(cache_c.X_bin)

# select random rows and cols
ğ‘– = cache_c.ğ‘–_[sample(params.rng, cache_c.ğ‘–_, ceil(Int, params_c.rowsample * X_size[1]), replace=false, ordered=true)]
ğ‘— = cache_c.ğ‘—_[sample(params.rng, cache_c.ğ‘—_, ceil(Int, params_c.colsample * X_size[2]), replace=false, ordered=true)]
# reset gain to -Inf
for feat in cache_c.ğ‘—_
    splits[feat].gain = -Inf
end

# build a new tree
# 897.800 Î¼s (6 allocations: 736 bytes)
@btime EvoTrees.update_grads!(params_c.loss, params_c.Î±, cache_c.pred, cache_c.Y, cache_c.Î´, cache_c.Î´Â², cache_c.ğ‘¤)
âˆ‘Î´, âˆ‘Î´Â², âˆ‘ğ‘¤ = sum(cache_c.Î´[ğ‘–]), sum(cache_c.Î´Â²[ğ‘–]), sum(cache_c.ğ‘¤[ğ‘–])
gain = EvoTrees.get_gain(params_c.loss, âˆ‘Î´, âˆ‘Î´Â², âˆ‘ğ‘¤, params_c.Î»)
# assign a root and grow tree
train_nodes[1] = EvoTrees.TrainNode(0, 1, âˆ‘Î´, âˆ‘Î´Â², âˆ‘ğ‘¤, gain, ğ‘–, ğ‘—)
# 69.247 ms (1852 allocations: 38.41 MiB)
@btime tree = grow_tree(cache_c.Î´, cache_c.Î´Â², cache_c.ğ‘¤, cache_c.hist_Î´, cache_c.hist_Î´Â², cache_c.hist_ğ‘¤, params_c, train_nodes, splits, cache_c.edges, cache_c.X_bin);
push!(model_c.trees, tree)
@btime EvoTrees.predict!(cache_c.pred, tree, cache_c.X)

###########################
# Tree CPU
###########################
Î´, Î´Â², ğ‘¤, hist_Î´, hist_Î´Â², hist_ğ‘¤, edges, X_bin = cache_c.Î´, cache_c.Î´Â², cache_c.ğ‘¤, cache_c.hist_Î´, cache_c.hist_Î´Â², cache_c.hist_ğ‘¤, cache_c.edges, cache_c.X_bin;

T = Float32
L = 1
active_id = ones(Int, 1)
leaf_count = one(Int)
tree_depth = one(Int)
tree = EvoTrees.Tree(Vector{EvoTrees.TreeNode{L,T,Int,Bool}}())

id = 1
node = train_nodes[id]
# 9.613 ms (81 allocations: 13.55 KiB)
@btime EvoTrees.update_hist!(hist_Î´[id], hist_Î´Â²[id], hist_ğ‘¤[id], Î´, Î´Â², ğ‘¤, X_bin, node)
# 601.685 ns (6 allocations: 192 bytes) 8 100 feat ~ 60us
@btime EvoTrees.find_split!(view(hist_Î´[id], :, j), view(hist_Î´Â²[id], :, j), view(hist_ğ‘¤[id], :, j), params, node, splits[j], edges[j])

###################################################
# GPU
###################################################
params_g = EvoTreeRegressor(T=Float32,
    loss=:linear, metric=:none,
    nrounds=100,
    Î»=1.0, Î³=0.1, Î·=0.1,
    max_depth=6, min_weight=1.0,
    rowsample=1.0, colsample=1.0, nbins=32);

model_g, cache_g = EvoTrees.init_evotree_gpu(params_g, X_train, Y_train);

params_g = model_g.params;
train_nodes = cache_g.train_nodes;
splits = cache_g.splits;
X_size = size(cache_g.X_bin);

# select random rows and cols
ğ‘– = cache_g.ğ‘–_[sample(params_g.rng, cache_g.ğ‘–_, ceil(Int, params_g.rowsample * X_size[1]), replace=false, ordered=true)]
ğ‘— = cache_g.ğ‘—_[sample(params_g.rng, cache_g.ğ‘—_, ceil(Int, params_g.colsample * X_size[2]), replace=false, ordered=true)]
# reset gain to -Inf
for feat in cache_g.ğ‘—_
    splits[feat].gain = -Inf
end

# build a new tree
# 164.200 Î¼s (33 allocations: 1.66 KiB) - 5-6 X time faster on GPU
@btime CUDA.@sync EvoTrees.update_grads_gpu!(params_g.loss, cache_g.Î´, cache_g.Î´Â², cache_g.pred, cache_g.Y, cache_g.ğ‘¤)
# sum Gradients of each of the K parameters and bring to CPU
âˆ‘Î´, âˆ‘Î´Â², âˆ‘ğ‘¤ = Vector(vec(sum(cache_g.Î´[ğ‘–,:], dims=1))), Vector(vec(sum(cache_g.Î´Â²[ğ‘–,:], dims=1))), sum(cache_g.ğ‘¤[ğ‘–])
gain = EvoTrees.get_gain(params_g.loss, âˆ‘Î´, âˆ‘Î´Â², âˆ‘ğ‘¤, params_g.Î»)
# assign a root and grow tree
train_nodes[1] = EvoTrees.TrainNode_gpu(0, 1, âˆ‘Î´, âˆ‘Î´Â², âˆ‘ğ‘¤, gain, ğ‘–, ğ‘—)
# 60.736 ms (108295 allocations: 47.95 MiB) - only 15% faster than CPU
@btime CUDA.@sync tree = EvoTrees.grow_tree_gpu(cache_g.Î´, cache_g.Î´Â², cache_g.ğ‘¤, cache_g.hist_Î´, cache_g.hist_Î´Â², cache_g.hist_ğ‘¤, params_g, cache_g.K, train_nodes, splits, cache_g.edges, cache_g.X_bin, cache_g.X_bin_cpu);
push!(model_g.trees, tree);
# 2.736 ms (93 allocations: 13.98 KiB)
@btime CUDA.@sync EvoTrees.predict_gpu!(cache_g.pred_cpu, tree, cache_g.X)
# 1.013 ms (37 allocations: 1.19 KiB)
@btime CUDA.@sync cache_g.pred .= CuArray(cache_g.pred_cpu);


###########################
# Tree GPU
###########################
Î´, Î´Â², ğ‘¤, hist_Î´, hist_Î´Â², hist_ğ‘¤, K, edges, X_bin, X_bin_cpu = cache_g.Î´, cache_g.Î´Â², cache_g.ğ‘¤, cache_g.hist_Î´, cache_g.hist_Î´Â², cache_g.hist_ğ‘¤, cache_g.K, cache_g.edges, cache_g.X_bin, cache_g.X_bin_cpu;
T = Float32
active_id = ones(Int, 1)
leaf_count = one(Int)
tree_depth = one(Int)
tree = EvoTrees.Tree_gpu(Vector{EvoTrees.TreeNode_gpu{T,Int,Bool}}())

hist_Î´_cpu = zeros(T, size(hist_Î´[1]));
hist_Î´Â²_cpu = zeros(T, size(hist_Î´Â²[1]));
hist_ğ‘¤_cpu = zeros(T, size(hist_ğ‘¤[1]));

id = 1
node = train_nodes[id];
# 7.003 ms (106 allocations: 3.09 KiB)
@btime CUDA.@sync EvoTrees.update_hist_gpu!(hist_Î´[id], hist_Î´Â²[id], hist_ğ‘¤[id], Î´, Î´Â², ğ‘¤, X_bin, CuVector(node.ğ‘–), CuVector(node.ğ‘—), K);
#  32.001 Î¼s (2 allocations: 32 bytes) * 3 adds 100us
@btime hist_Î´_cpu .= hist_Î´[id];
j = 1
# 2.925 Î¼s (78 allocations: 6.72 KiB) * 100 features ~ 300us
@btime EvoTrees.find_split_gpu!(view(hist_Î´_cpu, :, :, j), view(hist_Î´Â²_cpu, :, :, j), view(hist_ğ‘¤_cpu, :, j), params, node, splits[j], edges[j])