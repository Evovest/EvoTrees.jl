"""
    build a single histogram containing all grads and weight information
"""
# GPU - apply along the features axis
# function hist_kernel!(h::CuDeviceArray{T,4}, Î´::CuDeviceMatrix{T}, idx::CuDeviceMatrix{UInt8}, 
#     ğ‘–::CuDeviceVector{S}, ğ‘—::CuDeviceVector{S}, ğ‘›::CuDeviceVector{S}, L) where {T,S}

#     it = threadIdx().x
#     id = blockDim().x
#     ib = blockIdx().x
#     ig = gridDim().x

#     # k = blockIdx().z
#     # i = threadIdx().x + (blockIdx().x - 1) * blockDim().x

#     j = threadIdx().y + (blockIdx().y - 1) * blockDim().y

#     i_tot = length(ğ‘–)
#     iter = 0
#     while iter * id * ig < i_tot
#         i = it + id * (ib - 1) + iter * id * ig
#         if i <= length(ğ‘–) && j <= length(ğ‘—)
#             n = ğ‘›[i]
#             if n > 0
#                 pt = Base._to_linear_index(h, 1, idx[ğ‘–[i], ğ‘—[j]], ğ‘—[j], n)
#                 for k in 1:L
                    # CUDA.atomic_add!(pointer(h, pt + k - 1), Î´[ğ‘–[i], k])
#                 end
#             end
#         end
#         iter += 1
#     end
#     return nothing
# end


function hist_kernel!(h::CuDeviceArray{T,4}, Î´::CuDeviceMatrix{T}, xid::CuDeviceMatrix{UInt8}, 
    ğ‘–::CuDeviceVector{S}, ğ‘—::CuDeviceVector{S}, ğ‘›::CuDeviceVector{S}, depth) where {T,S}
    
    nbins = size(h, 2)

    it = threadIdx().x
    id, jd = blockDim().x, blockDim().y
    ib, j, k = blockIdx().x, blockIdx().y, blockIdx().z
    ig, jg = gridDim().x, gridDim().y
    
    shared = @cuDynamicSharedMem(T, (size(h, 2), size(h, 4)))
    fill!(shared, 0)
    sync_threads()

    i_tot = length(ğ‘–)
    iter = 0
    while iter * id * ig < i_tot
        i = it + id * (ib - 1) + iter * id * ig
        if i <= length(ğ‘–) && j <= length(ğ‘—)
            # depends on shared to be assigned to a single feature
            @inbounds i_idx = ğ‘–[i]
            @inbounds n = ğ‘›[i_idx]
            # if n != 0
            @inbounds CUDA.atomic_add!(pointer(shared, xid[i_idx, ğ‘—[j]] + nbins * (n - 1)), Î´[i_idx, k])
            # @inbounds shared[xid[i_idx, ğ‘—[j]] + nbins * (n-1)] += Î´[i_idx, k]
            # end
        end
        iter += 1
    end
    sync_threads()
    # loop over nodes of given depth
    for nid âˆˆ 2^(depth - 1):2^(depth) - 1
        # n = 1 # need to loop over nodes
        if it <= nbins
            @inbounds hid = Base._to_linear_index(h, k, it, ğ‘—[j], nid)
            @inbounds CUDA.atomic_add!(pointer(h, hid), shared[it, nid])
        end
    end
    sync_threads()
    return nothing
end

# base approach - block built along the cols first, the rows (limit collisions)
function update_hist_gpu!(
    h::CuArray{T,4}, 
    Î´::CuMatrix{T}, 
    X_bin::CuMatrix{UInt8}, 
    ğ‘–::CuVector{S}, 
    ğ‘—::CuVector{S}, 
    ğ‘›::CuVector{S}, depth; 
    MAX_THREADS=256) where {T,S}
    
    fill!(h, 0.0)
    thread_i = min(MAX_THREADS, length(ğ‘–))
    threads = (thread_i,)
    blocks = (1, length(ğ‘—), 3)
    # blocks = (ceil(Int, length(ğ‘–) / thread_i), length(ğ‘—))
    @cuda blocks = blocks threads = threads shmem = sizeof(T) * size(h, 2) * size(h, 4) hist_kernel!(h, Î´, X_bin, ğ‘–, ğ‘—, ğ‘›, depth)
    return
end

# update the vector of length ğ‘– pointing to associated node id
function update_set_kernel!(ğ‘›, ğ‘–, X_bin, feats, bins, nbins)
    it = threadIdx().x
    ibd = blockDim().x
    ibi = blockIdx().x
    i = it + ibd * (ibi - 1)

    if i <= length(ğ‘–)
        @inbounds idx = ğ‘–[i]
        @inbounds feat = feats[ğ‘›[idx]]
        @inbounds cond = bins[ğ‘›[idx]]
        @inbounds if cond == 0
            ğ‘›[idx] = 0
        elseif X_bin[idx, feat] <= cond
            ğ‘›[idx] = ğ‘›[idx] << 1 
        else
            ğ‘›[idx] = ğ‘›[idx] << 1 + 1
        end
    end
    return nothing
end

function update_set_gpu!(ğ‘›, ğ‘–, X_bin, feats, bins, nbins; MAX_THREADS=1024)
    thread_i = min(MAX_THREADS, length(ğ‘–))
    threads = thread_i
    blocks = length(ğ‘–) Ã· thread_i + 1
    @cuda blocks = blocks threads = threads update_set_kernel!(ğ‘›, ğ‘–, X_bin, feats, bins, nbins)
    return
end

# split row ids into left and right based on best split condition
function update_set!(ğ‘›, ğ‘–, X_bin, feats, bins, nbins)
    
    @inbounds for i in ğ‘–
        feat = feats[ğ‘›[i]]
        cond = bins[ğ‘›[i]]
        if cond == nbins
            ğ‘›[ğ‘–] = 0
        elseif X_bin[i, feat] <= cond
            ğ‘›[i] = ğ‘›[i] << 1 
        else
            ğ‘›[i] = ğ‘›[i] << 1 + 1
        end
    end
    return nothing
end


# operate on hist_gpu
"""
find_split_gpu!
    Find best split over gpu histograms
"""

function update_gains_gpu!(
    gains::AbstractArray{T,3},
    hist::AbstractArray{T,4}, 
    histL::AbstractArray{T,4}, 
    histR::AbstractArray{T,4},
    ğ‘—::AbstractVector{S},
    params::EvoTypes,
    nid, depth) where {T,S}

    cumsum!(view(histL, :, :, :, nid), view(hist, :, :, :, nid), dims=2)
    # cumsum!(view(histR, :, :, :, nid), reverse!(view(hist, :, :, :, nid), dims=2), dims=2)
    view(histR, :, :, :, nid) .= view(histL, :, params.nbins:params.nbins, :, nid) .- view(histL, :, :, :, nid)
    hist_gains_gpu!(gains, histL, histR, ğ‘—, params.nbins, depth, params.Î»)

    return nothing
end


function hist_gains_gpu_kernel!(gains::CuDeviceArray{T,3}, hL::CuDeviceArray{T,4}, hR::CuDeviceArray{T,4}, ğ‘—::CuDeviceVector{S}, nbins, depth, Î»::T) where {T,S}
    
    i = threadIdx().x
    j = ğ‘—[blockIdx().x]
    n = blockIdx().y + 2^(depth - 1) - 1

    @inbounds if hL[3, i, j, n] > 1e-5 && hR[3, i, j, n] > 1e-5
        gains[i, j, n] = (hL[1, i, j, n]^2 / (hL[2, i, j, n] + Î» * hL[3, i, j, n]) + 
            hR[1, i, j, n]^2 / (hR[2, i, j, n] + Î» * hR[3, i, j, n])) / 2
    elseif i == nbins
        gains[i, j, n] = hL[1, i, j, n]^2 / (hL[2, i, j, n] + Î» * hL[3, i, j, n]) / 2 
    end
    return nothing
end

function hist_gains_gpu!(gains::CuArray{T,3}, hL::CuArray{T,4}, hR::CuArray{T,4}, ğ‘—::CuVector{S}, nbins, depth, Î»::T; MAX_THREADS=256) where {T,S}
    thread_i = min(nbins, MAX_THREADS)
    threads = thread_i
    blocks = length(ğ‘—), 2^(depth - 1)
    @cuda blocks = blocks threads = threads hist_gains_gpu_kernel!(gains, hL, hR, ğ‘—, nbins, depth, Î»)
    return gains
end
