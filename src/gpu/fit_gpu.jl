# initialise evotree
function init_evotree_gpu(params::EvoTypes{T,U,S},
    X::AbstractMatrix, Y::AbstractVector; verbosity=1) where {T,U,S}

    K = 1
    levels = ""
    X = convert(Matrix{T}, X)
    if typeof(params.loss) == Logistic
        Y_cpu = T.(Y)
        Y = CuArray(Y_cpu)
        Î¼ = [logit(mean(Y))]
    elseif typeof(params.loss) == Poisson
        Y_cpu = T.(Y)
        Y = CuArray(Y_cpu)
        Î¼ = fill(log(mean(Y)), 1)
    elseif typeof(params.loss) == Softmax
        if typeof(Y) <: AbstractCategoricalVector
            levels = CategoricalArray(CategoricalArrays.levels(Y))
            K = length(levels)
            Î¼ = zeros(T, K)
            Y = MLJModelInterface.int.(Y)
        else
            levels = CategoricalArray(sort(unique(Y)))
            K = length(levels)
            Î¼ = zeros(T, K)
            Y = UInt32.(Y)
        end
    elseif typeof(params.loss) == Gaussian
        K = 2
        Y_cpu = T.(Y)
        Y = CuArray(Y_cpu)
        Î¼ = [mean(Y), log(std(Y))]
    else
        Y_cpu = T.(Y)
        Y = CuArray(Y_cpu)
        Î¼ = [mean(Y)]
    end

    # initialize preds
    X_size = size(X)
    pred_cpu = zeros(T, X_size[1], K)
    pred_gpu = CUDA.zeros(T, X_size[1], K)
    pred_cpu .= Î¼'
    pred_gpu .= CuArray(Î¼)'

    bias = TreeGPU([TreeNodeGPU(Î¼)])
    evotree = GBTreeGPU([bias], params, Metric(), UInt32(K), levels)

    ğ‘–_ = UInt32.(collect(1:X_size[1]))
    ğ‘—_ = UInt32.(collect(1:X_size[2]))

    # initialize gradients and weights
    Î´ = CUDA.ones(T, X_size[1], 2 * K + 1)

    # binarize data into quantiles
    edges = get_edges(X, params.nbins)
    X_bin_cpu = binarize(X, edges)
    X_bin = CuArray(X_bin_cpu)

    # initializde histograms
    hist = [CUDA.zeros(T, 2 * K + 1, params.nbins, X_size[2]) for i in 1:2^params.max_depth - 1]

    # initialize train nodes
    train_nodes = Vector{TrainNodeGPU{T,UInt32,CuVector{UInt32},Vector{T}}}(undef, 2^params.max_depth - 1)

    # store cache
    cache = (params = deepcopy(params),
        X = X, Y = Y, Y_cpu = Y_cpu, K = K,
        pred_gpu = pred_gpu, pred_cpu = pred_cpu,
        ğ‘–_ = ğ‘–_, ğ‘—_ = ğ‘—_, 
        Î´ = Î´,
        edges = edges,
        X_bin = X_bin,
        train_nodes = train_nodes,
        # splits = splits,
        hist = hist)

    cache.params.nrounds = 0

    return evotree, cache
end


function grow_evotree!(evotree::GBTreeGPU{T,S}, cache; verbosity=1) where {T,S}

    # initialize from cache
    params = evotree.params
    train_nodes = cache.train_nodes
    X_size = size(cache.X_bin)
    Î´nrounds = params.nrounds - cache.params.nrounds

    # loop over nrounds
    for i in 1:Î´nrounds

        # select random rows and cols
        ğ‘– = CuVector(cache.ğ‘–_[sample(params.rng, cache.ğ‘–_, ceil(Int, params.rowsample * X_size[1]), replace=false, ordered=true)])
        ğ‘— = CuVector(cache.ğ‘—_[sample(params.rng, cache.ğ‘—_, ceil(Int, params.colsample * X_size[2]), replace=false, ordered=true)])

        # build a new tree
        update_grads_gpu!(params.loss, cache.Î´, cache.pred_gpu, cache.Y)

        # âˆ‘ = vec(sum(cache.Î´[ğ‘–,:], dims=1))
        âˆ‘ = Array(vec(sum(cache.Î´[ğ‘–,:], dims=1)))

        gain = get_gain_gpu(params.loss, âˆ‘, params.Î»)
        # # assign a root and grow tree
        train_nodes[1] = TrainNodeGPU(S(0), S(1), âˆ‘, gain, ğ‘–, ğ‘—)
        tree = grow_tree(cache.Î´, cache.hist, params, cache.K, train_nodes, cache.edges, cache.X_bin)
        push!(evotree.trees, tree)
        # bad GPU usage - to be improved!
        predict!(cache.pred_cpu, tree, cache.X)
        cache.pred_gpu .= CuArray(cache.pred_cpu)

    end # end of nrounds

    cache.params.nrounds = params.nrounds
    # return model, cache
    return evotree
end

# grow a single tree - grow through all depth
function grow_tree(Î´, hist, 
    params::EvoTypes{T,U,R}, K,
    train_nodes::Vector{TrainNodeGPU{T,S,I,V}},
    edges, X_bin) where {T,U,R,S,I,V}

    active_id = ones(S, 1)
    leaf_count = one(S)
    tree_depth = one(S)
    tree = TreeGPU(Vector{TreeNodeGPU{T,S,Bool}}())

    hist_cpu = zeros(T, size(hist[1]))

    # grow while there are remaining active nodes
    while size(active_id, 1) > 0 && tree_depth <= params.max_depth
        next_active_id = ones(S, 0)
        # grow nodes
        for id in active_id
            node = train_nodes[id]
            if tree_depth == params.max_depth || node.âˆ‘[end] <= params.min_weight + 0.1 # rounding needed from histogram substraction
                push!(tree.nodes, TreeNodeGPU(pred_leaf_gpu(params.loss, node, params)))
            else
                
                if id > 1 && id == tree.nodes[node.parent].right
                    # hist[id] = hist[node.parent] - hist[id - 1]
                    update_hist_gpu!(hist[id], Î´, X_bin, node.ğ‘–, node.ğ‘—, K)
                else
                    update_hist_gpu!(hist[id], Î´, X_bin, node.ğ‘–, node.ğ‘—, K)
                end

                best = find_split_gpu!(hist[id], edges, node.ğ‘—, params)
                # grow node if best split improves gain
                if best[:gain] > node.gain + params.Î³ + 1e-5 && best[:âˆ‘L][end] > 1e-5 && best[:âˆ‘R][end] > 1e-5
                    # if best[:gain] > node.gain + params.Î³
    
                    left, right = update_set_gpu(node.ğ‘–, best[:bin], X_bin[:, best[:feat]])
                    train_nodes[leaf_count + 1] = TrainNodeGPU(id, node.depth + S(1), best[:âˆ‘L], best[:gainL], left, node.ğ‘—)
                    train_nodes[leaf_count + 2] = TrainNodeGPU(id, node.depth + S(1), best[:âˆ‘R], best[:gainR], right, node.ğ‘—)
                    push!(tree.nodes, TreeNodeGPU(leaf_count + S(1), leaf_count + S(2), best[:feat], best[:cond], best[:gain] - node.gain, K))
    
                    push!(next_active_id, leaf_count + S(1))
                    push!(next_active_id, leaf_count + S(2))
                    leaf_count += S(2)
                else
                    push!(tree.nodes, TreeNodeGPU(pred_leaf_gpu(params.loss, node, params)))
                end # end of single node split search
            end
        end # end of loop over active ids for a given depth
        active_id = next_active_id
        tree_depth += S(1)
    end # end of tree growth
    return tree
end