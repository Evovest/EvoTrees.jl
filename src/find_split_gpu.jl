# GPU - apply along the features axis
function kernel_v1!(h::CuDeviceMatrix{T}, x::CuDeviceMatrix{T}, id) where {T<:AbstractFloat}
    i = threadIdx().x + (blockIdx().x - 1) * blockDim().x
    j = threadIdx().y + (blockIdx().y - 1) * blockDim().y
    @inbounds if i <= size(id, 1) && j <= size(h, 2)
        k = Base._to_linear_index(h, id[i,j], j)
        CUDAnative.atomic_add!(pointer(h, k), x[i,j])
    end
    return
end

function hist_gpu_v1!(h::CuMatrix{T}, x::CuMatrix{T}, id::CuMatrix{Int}; MAX_THREADS=512) where {T<:AbstractFloat}
    thread_j = min(MAX_THREADS, size(id, 2))
    thread_i = min(MAX_THREADS Ã· thread_j, size(h, 1))
    threads = (thread_i, thread_j)
    blocks = ceil.(Int, (size(id, 1), size(h, 2)) ./ threads)
    CuArrays.@cuda blocks=blocks threads=threads kernel_v1!(h, x, id)
    return h
end

function update_hist_gpu!(hist_Î´::Matrix{SVector{L,T}}, hist_Î´Â²::Matrix{SVector{L,T}}, hist_ğ‘¤::Matrix{SVector{1,T}},
    Î´::Vector{SVector{L,T}}, Î´Â²::Vector{SVector{L,T}}, ğ‘¤::Vector{SVector{1,T}},
    X_bin, node::TrainNode{L,T,S}) where {L,T,S}

    hist_Î´ .*= 0.0
    hist_Î´Â² .*= 0.0
    hist_ğ‘¤ .*= 0.0

    hist_gpu_v1!(hist_Î´, Î´, id)
    hist_gpu_v1!(hist_Î´Â², Î´Â², id)
    hist_gpu_v1!(hist_ğ‘¤, ğ‘¤, id)
    # @inbounds @threads for j in node.ğ‘—
    #     @inbounds for i in node.ğ‘–
    #         hist_Î´[X_bin[i,j], j] += Î´[i]
    #         hist_Î´Â²[X_bin[i,j], j] += Î´Â²[i]
    #         hist_ğ‘¤[X_bin[i,j], j] += ğ‘¤[i]
    #     end
    # end
end

function find_split_gpu!(hist_Î´::AbstractVector{SVector{L,T}}, hist_Î´Â²::AbstractVector{SVector{L,T}}, hist_ğ‘¤::AbstractVector{SVector{1,T}},
    params::EvoTypes, node::TrainNode{L,T,S}, info::SplitInfo{L,T,S}, edges::Vector{T}) where {L,T,S}

    # initialize tracking
    âˆ‘Î´L = node.âˆ‘Î´ * 0
    âˆ‘Î´Â²L = node.âˆ‘Î´Â² * 0
    âˆ‘ğ‘¤L = node.âˆ‘ğ‘¤ * 0
    âˆ‘Î´R = node.âˆ‘Î´
    âˆ‘Î´Â²R = node.âˆ‘Î´Â²
    âˆ‘ğ‘¤R = node.âˆ‘ğ‘¤

    @inbounds for bin in 1:(length(hist_Î´)-1)
        âˆ‘Î´L += hist_Î´[bin]
        âˆ‘Î´Â²L += hist_Î´Â²[bin]
        âˆ‘ğ‘¤L += hist_ğ‘¤[bin]
        âˆ‘Î´R -= hist_Î´[bin]
        âˆ‘Î´Â²R -= hist_Î´Â²[bin]
        âˆ‘ğ‘¤R -= hist_ğ‘¤[bin]

        gainL, gainR = get_gain(params.loss, âˆ‘Î´L, âˆ‘Î´Â²L, âˆ‘ğ‘¤L, params.Î»), get_gain(params.loss, âˆ‘Î´R, âˆ‘Î´Â²R, âˆ‘ğ‘¤R, params.Î»)
        gain = gainL + gainR

        if gain > info.gain && âˆ‘ğ‘¤L[1] >= params.min_weight + 1e-12 && âˆ‘ğ‘¤R[1] >= params.min_weight + 1e-12
            info.gain = gain
            info.gainL = gainL
            info.gainR = gainR
            info.âˆ‘Î´L = âˆ‘Î´L
            info.âˆ‘Î´Â²L = âˆ‘Î´Â²L
            info.âˆ‘ğ‘¤L = âˆ‘ğ‘¤L
            info.âˆ‘Î´R = âˆ‘Î´R
            info.âˆ‘Î´Â²R = âˆ‘Î´Â²R
            info.âˆ‘ğ‘¤R = âˆ‘ğ‘¤R
            info.cond = edges[bin]
            info.ğ‘– = bin
        end # info update if gain
    end # loop on bins
end


function find_split_gpu_test!(hist_Î´::Vector{SVector{L,T}}, hist_Î´Â²::Vector{SVector{L,T}}, hist_ğ‘¤::Vector{SVector{1,T}}, bins::Vector{BitSet}, X_bin, Î´::Vector{SVector{L,T}}, Î´Â²::Vector{SVector{L,T}}, ğ‘¤::Vector{SVector{1,T}}, âˆ‘Î´::SVector{L,T}, âˆ‘Î´Â²::SVector{L,T}, âˆ‘ğ‘¤::SVector{1,T}, params::EvoTreeRegressor, info::SplitInfo{L,T,S}, edges::Vector{T}, set::Vector{S}) where {L,T,S}

    # initialize histogram
    hist_Î´ .*= 0.0
    hist_Î´Â² .*= 0.0
    hist_ğ‘¤ .*= 0.0

    # build histogram
    @inbounds for i in set
        hist_Î´[X_bin[i]] += Î´[i]
        hist_Î´Â²[X_bin[i]] += Î´Â²[i]
        hist_ğ‘¤[X_bin[i]] += ğ‘¤[i]
    end
    return
end
