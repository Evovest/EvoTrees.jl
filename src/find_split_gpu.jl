# GPU - apply along the features axis
function hist_kernel!(h::CuDeviceArray{T,3}, x::CuDeviceMatrix{T}, id, ğ‘–, ğ‘—, K) where {T<:AbstractFloat}
    i = threadIdx().x + (blockIdx().x - 1) * blockDim().x
    j = threadIdx().y + (blockIdx().y - 1) * blockDim().y
    if i <= length(ğ‘–) && j <= length(ğ‘—)
        for k in 1:K
            @inbounds pt = Base._to_linear_index(h, id[ğ‘–[i], ğ‘—[j]], k, ğ‘—[j])
            @inbounds CUDA.atomic_add!(pointer(h, pt), x[ğ‘–[i],k])
        end
    end
    return
end

# for 2D input like ğ‘¤ (single input)
function hist_kernel!(h::CuDeviceMatrix{T}, x::CuDeviceVector{T}, id, ğ‘–, ğ‘—) where {T<:AbstractFloat}
    i = threadIdx().x + (blockIdx().x - 1) * blockDim().x
    j = threadIdx().y + (blockIdx().y - 1) * blockDim().y
    if i <= length(ğ‘–) && j <= length(ğ‘—)
        @inbounds pt = Base._to_linear_index(h, id[ğ‘–[i], ğ‘—[j]], ğ‘—[j])
        @inbounds CUDA.atomic_add!(pointer(h, pt), x[ğ‘–[i]])
    end
    return
end

# base approach - block built along the cols first, the rows (limit collisions)
function hist_gpu!(h_Î´::CuArray{T,3}, h_Î´Â²::CuArray{T,3}, h_ğ‘¤::CuMatrix{T},
    Î´::CuMatrix{T}, Î´Â²::CuMatrix{T}, ğ‘¤::CuVector{T},
    X_bin::CuMatrix{Int}, ğ‘–::CuVector{Int}, ğ‘—::CuVector{Int}, K; MAX_THREADS=1024) where {T<:AbstractFloat}

    h_Î´ .= 0.0
    h_Î´Â² .= 0.0
    h_ğ‘¤ .= 0.0

    thread_j = min(MAX_THREADS, length(ğ‘—))
    thread_i = min(MAX_THREADS Ã· thread_j, length(ğ‘–))
    threads = (thread_i, thread_j)
    blocks = ceil.(Int, (length(ğ‘–), length(ğ‘—)) ./ threads)

    @cuda blocks=blocks threads=threads hist_kernel!(h_Î´, Î´, X_bin, ğ‘–, ğ‘—, K)
    @cuda blocks=blocks threads=threads hist_kernel!(h_Î´Â², Î´Â², X_bin, ğ‘–, ğ‘—, K)
    @cuda blocks=blocks threads=threads hist_kernel!(h_ğ‘¤, ğ‘¤, X_bin, ğ‘–, ğ‘—)
    return
end

function update_hist_gpu!(hist_Î´::Matrix{SVector{L,T}}, hist_Î´Â²::Matrix{SVector{L,T}}, hist_ğ‘¤::Matrix{SVector{1,T}},
    Î´::Vector{SVector{L,T}}, Î´Â²::Vector{SVector{L,T}}, ğ‘¤::Vector{SVector{1,T}},
    X_bin, node::TrainNode{L,T,S}) where {L,T,S}

    hist_Î´ .*= 0.0
    hist_Î´Â² .*= 0.0
    hist_ğ‘¤ .*= 0.0

    hist_gpu!(hist_Î´, Î´, id)
    hist_gpu!(hist_Î´Â², Î´Â², id)
    hist_gpu!(hist_ğ‘¤, ğ‘¤, id)

end


function find_split_gpu!(hist_Î´::AbstractMatrix{T}, hist_Î´Â²::AbstractMatrix{T}, hist_ğ‘¤::AbstractVector{T},
    params::EvoTypes, node::TrainNode_gpu{T,S}, info::SplitInfo_gpu{T,S}, edges::Vector{T}) where {T,S}

    # initialize tracking
    âˆ‘Î´L = node.âˆ‘Î´ .* 0
    âˆ‘Î´Â²L = node.âˆ‘Î´Â² .* 0
    âˆ‘ğ‘¤L = node.âˆ‘ğ‘¤ * 0
    âˆ‘Î´R = node.âˆ‘Î´
    âˆ‘Î´Â²R = node.âˆ‘Î´Â²
    âˆ‘ğ‘¤R = node.âˆ‘ğ‘¤

    @inbounds for bin in 1:(length(hist_Î´)-1)
        âˆ‘Î´L .+= hist_Î´[bin,:]
        âˆ‘Î´Â²L .+= hist_Î´Â²[bin,:]
        âˆ‘ğ‘¤L += hist_ğ‘¤[bin]
        âˆ‘Î´R .-= hist_Î´[bin,:]
        âˆ‘Î´Â²R .-= hist_Î´Â²[bin,:]
        âˆ‘ğ‘¤R -= hist_ğ‘¤[bin]

        gainL, gainR = get_gain(params.loss, âˆ‘Î´L, âˆ‘Î´Â²L, âˆ‘ğ‘¤L, params.Î»), get_gain(params.loss, âˆ‘Î´R, âˆ‘Î´Â²R, âˆ‘ğ‘¤R, params.Î»)
        gain = gainL + gainR

        if gain > info.gain && âˆ‘ğ‘¤L >= params.min_weight + 1e-12 && âˆ‘ğ‘¤R >= params.min_weight + 1e-12
            info.gain = gain
            info.gainL = gainL
            info.gainR = gainR
            info.âˆ‘Î´L .= âˆ‘Î´L
            info.âˆ‘Î´Â²L .= âˆ‘Î´Â²L
            info.âˆ‘ğ‘¤L = âˆ‘ğ‘¤L
            info.âˆ‘Î´R .= âˆ‘Î´R
            info.âˆ‘Î´Â²R .= âˆ‘Î´Â²R
            info.âˆ‘ğ‘¤R = âˆ‘ğ‘¤R
            info.cond = edges[bin]
            info.ğ‘– = bin
        end # info update if gain
    end # loop on bins
end
